[
    {
        "agent": "build",
        "total_seconds": 231.4147337859995,
        "result": "# Dockerfile for LAMMPS (Large-scale Atomic/Molecular Massively Parallel Simulator)\n# Target Environment: Google Cloud CPU instance in Kubernetes\n# Base Image: Ubuntu 22.04 LTS for a stable and widely supported environment\nFROM ubuntu:22.04\n\n# Set DEBIAN_FRONTEND to noninteractive to prevent prompts during package installation\nENV DEBIAN_FRONTEND=noninteractive\n\n# Install build dependencies for LAMMPS\n# Includes git for cloning, cmake/build-essential for compiling,\n# and OpenMPI for parallel processing on CPU clusters.\n# FFTW is a common dependency for many LAMMPS packages.\n# CORRECTED: Added ca-certificates to allow git to verify SSL certificates for HTTPS clones.\n# The apt cache is cleaned in the same layer to reduce image size.\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    build-essential \\\n    cmake \\\n    git \\\n    libopenmpi-dev \\\n    openmpi-bin \\\n    libfftw3-dev \\\n    python3-dev \\\n    ca-certificates \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Configure OpenMPI for containerized environments like Docker and Kubernetes.\n# These settings are critical for running MPI jobs in containers:\n# - btl_tcp_if_exclude: Prevents MPI from using internal container network interfaces.\n# - orte_allow_run_as_root: Allows MPI processes to be launched by the root user, as is common in containers.\n# - rmaps_base_oversubscribe: Allows running more MPI processes than available CPU cores, useful for node sharing.\nRUN echo \"btl_tcp_if_exclude = lo,docker0\" >> /etc/openmpi/openmpi-mca-params.conf && \\\n    echo \"orte_allow_run_as_root = 1\" >> /etc/openmpi/openmpi-mca-params.conf && \\\n    echo \"rmaps_base_oversubscribe = 1\" >> /etc/openmpi/openmpi-mca-params.conf\n\n# Clone, build, and install LAMMPS from the latest branch in a single RUN layer.\n# This approach adheres to the no-multistage-build requirement.\n# --depth 1 is used to clone only the latest commit, speeding up the build.\n# A selection of common packages (KSPACE, MOLECULE, RIGID, REAXFF) is enabled for a robust, general-purpose build.\n# The executable 'lmp' will be installed to /usr/local/bin, which is on the system PATH.\nRUN git clone --depth 1 https://github.com/lammps/lammps.git /tmp/lammps && \\\n    cd /tmp/lammps && \\\n    mkdir build && \\\n    cd build && \\\n    cmake ../cmake \\\n        -D CMAKE_INSTALL_PREFIX=/usr/local \\\n        -D CMAKE_BUILD_TYPE=Release \\\n        -D BUILD_MPI=yes \\\n        -D PKG_KSPACE=yes \\\n        -D PKG_MOLECULE=yes \\\n        -D PKG_RIGID=yes \\\n        -D PKG_REAXFF=yes && \\\n    make -j$(nproc) && \\\n    make install\n\n# Set a working directory for running simulations.\nWORKDIR /opt/lammps_run\n\n# As requested, copy all files from the LAMMPS example 'examples/reaxff/HNS'\n# into the working directory, making them readily available for test runs.\nRUN cp /tmp/lammps/examples/reaxff/HNS/* .\n\n# Set the default command to an interactive bash shell.\n# This allows a user to easily exec into the container and launch LAMMPS simulations.\n# The LAMMPS executable 'lmp' is on the PATH and can be run directly.\n# Example usage: mpirun -np 4 lmp -in in.hns\nCMD [\"/bin/bash\"]",
        "attempts": 2,
        "metadata": {
            "times": {
                "generate_dockerfile_seconds": [
                    42.940620941000816,
                    15.887060630999258
                ],
                "build_seconds": [
                    22.471247796998796,
                    91.78324315600003
                ],
                "load_seconds": [
                    32.961922249000054
                ],
                "run_step_seconds": [
                    140.64563163499952,
                    231.41470636899976
                ]
            },
            "assets": {
                "dockerfile": [
                    {
                        "item": "# Dockerfile for LAMMPS (Large-scale Atomic/Molecular Massively Parallel Simulator)\n# Target Environment: Google Cloud CPU instance in Kubernetes\n# Base Image: Ubuntu 22.04 LTS for a stable and widely supported environment\nFROM ubuntu:22.04\n\n# Set DEBIAN_FRONTEND to noninteractive to prevent prompts during package installation\nENV DEBIAN_FRONTEND=noninteractive\n\n# Install build dependencies for LAMMPS\n# Includes git for cloning, cmake/build-essential for compiling,\n# and OpenMPI for parallel processing on CPU clusters.\n# FFTW is a common dependency for many LAMMPS packages.\n# The apt cache is cleaned in the same layer to reduce image size.\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    build-essential \\\n    cmake \\\n    git \\\n    libopenmpi-dev \\\n    openmpi-bin \\\n    libfftw3-dev \\\n    python3-dev \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Configure OpenMPI for containerized environments like Docker and Kubernetes.\n# These settings are critical for running MPI jobs in containers:\n# - btl_tcp_if_exclude: Prevents MPI from using internal container network interfaces.\n# - orte_allow_run_as_root: Allows MPI processes to be launched by the root user, as is common in containers.\n# - rmaps_base_oversubscribe: Allows running more MPI processes than available CPU cores, useful for node sharing.\nRUN echo \"btl_tcp_if_exclude = lo,docker0\" >> /etc/openmpi/openmpi-mca-params.conf && \\\n    echo \"orte_allow_run_as_root = 1\" >> /etc/openmpi/openmpi-mca-params.conf && \\\n    echo \"rmaps_base_oversubscribe = 1\" >> /etc/openmpi/openmpi-mca-params.conf\n\n# Clone, build, and install LAMMPS from the latest branch in a single RUN layer.\n# This approach adheres to the no-multistage-build requirement.\n# --depth 1 is used to clone only the latest commit, speeding up the build.\n# A selection of common packages (KSPACE, MOLECULE, RIGID, REAXFF) is enabled for a robust, general-purpose build.\n# The executable 'lmp' will be installed to /usr/local/bin, which is on the system PATH.\nRUN git clone --depth 1 https://github.com/lammps/lammps.git /tmp/lammps && \\\n    cd /tmp/lammps && \\\n    mkdir build && \\\n    cd build && \\\n    cmake ../cmake \\\n        -D CMAKE_INSTALL_PREFIX=/usr/local \\\n        -D CMAKE_BUILD_TYPE=Release \\\n        -D BUILD_MPI=yes \\\n        -D PKG_KSPACE=yes \\\n        -D PKG_MOLECULE=yes \\\n        -D PKG_RIGID=yes \\\n        -D PKG_REAXFF=yes && \\\n    make -j$(nproc) && \\\n    make install\n\n# Set a working directory for running simulations.\nWORKDIR /opt/lammps_run\n\n# As requested, copy all files from the LAMMPS example 'examples/reaxff/HNS'\n# into the working directory, making them readily available for test runs.\nRUN cp /tmp/lammps/examples/reaxff/HNS/* .\n\n# Set the default command to an interactive bash shell.\n# This allows a user to easily exec into the container and launch LAMMPS simulations.\n# The LAMMPS executable 'lmp' is on the PATH and can be run directly.\n# Example usage: mpirun -np 4 lmp -in in.hns\nCMD [\"/bin/bash\"]",
                        "attempt": 0
                    },
                    {
                        "item": "# Dockerfile for LAMMPS (Large-scale Atomic/Molecular Massively Parallel Simulator)\n# Target Environment: Google Cloud CPU instance in Kubernetes\n# Base Image: Ubuntu 22.04 LTS for a stable and widely supported environment\nFROM ubuntu:22.04\n\n# Set DEBIAN_FRONTEND to noninteractive to prevent prompts during package installation\nENV DEBIAN_FRONTEND=noninteractive\n\n# Install build dependencies for LAMMPS\n# Includes git for cloning, cmake/build-essential for compiling,\n# and OpenMPI for parallel processing on CPU clusters.\n# FFTW is a common dependency for many LAMMPS packages.\n# CORRECTED: Added ca-certificates to allow git to verify SSL certificates for HTTPS clones.\n# The apt cache is cleaned in the same layer to reduce image size.\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    build-essential \\\n    cmake \\\n    git \\\n    libopenmpi-dev \\\n    openmpi-bin \\\n    libfftw3-dev \\\n    python3-dev \\\n    ca-certificates \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Configure OpenMPI for containerized environments like Docker and Kubernetes.\n# These settings are critical for running MPI jobs in containers:\n# - btl_tcp_if_exclude: Prevents MPI from using internal container network interfaces.\n# - orte_allow_run_as_root: Allows MPI processes to be launched by the root user, as is common in containers.\n# - rmaps_base_oversubscribe: Allows running more MPI processes than available CPU cores, useful for node sharing.\nRUN echo \"btl_tcp_if_exclude = lo,docker0\" >> /etc/openmpi/openmpi-mca-params.conf && \\\n    echo \"orte_allow_run_as_root = 1\" >> /etc/openmpi/openmpi-mca-params.conf && \\\n    echo \"rmaps_base_oversubscribe = 1\" >> /etc/openmpi/openmpi-mca-params.conf\n\n# Clone, build, and install LAMMPS from the latest branch in a single RUN layer.\n# This approach adheres to the no-multistage-build requirement.\n# --depth 1 is used to clone only the latest commit, speeding up the build.\n# A selection of common packages (KSPACE, MOLECULE, RIGID, REAXFF) is enabled for a robust, general-purpose build.\n# The executable 'lmp' will be installed to /usr/local/bin, which is on the system PATH.\nRUN git clone --depth 1 https://github.com/lammps/lammps.git /tmp/lammps && \\\n    cd /tmp/lammps && \\\n    mkdir build && \\\n    cd build && \\\n    cmake ../cmake \\\n        -D CMAKE_INSTALL_PREFIX=/usr/local \\\n        -D CMAKE_BUILD_TYPE=Release \\\n        -D BUILD_MPI=yes \\\n        -D PKG_KSPACE=yes \\\n        -D PKG_MOLECULE=yes \\\n        -D PKG_RIGID=yes \\\n        -D PKG_REAXFF=yes && \\\n    make -j$(nproc) && \\\n    make install\n\n# Set a working directory for running simulations.\nWORKDIR /opt/lammps_run\n\n# As requested, copy all files from the LAMMPS example 'examples/reaxff/HNS'\n# into the working directory, making them readily available for test runs.\nRUN cp /tmp/lammps/examples/reaxff/HNS/* .\n\n# Set the default command to an interactive bash shell.\n# This allows a user to easily exec into the container and launch LAMMPS simulations.\n# The LAMMPS executable 'lmp' is on the PATH and can be run directly.\n# Example usage: mpirun -np 4 lmp -in in.hns\nCMD [\"/bin/bash\"]",
                        "attempt": 1
                    }
                ]
            },
            "ask_gemini": [
                {
                    "conversation_history": true,
                    "prompt_token_count": 229,
                    "candidates_token_count": 876,
                    "total_token_count": 4964,
                    "time_seconds": 42.93851666400042
                },
                {
                    "conversation_history": true,
                    "prompt_token_count": 2522,
                    "candidates_token_count": 902,
                    "total_token_count": 4444,
                    "time_seconds": 15.88503639100054
                }
            ],
            "retries": 0,
            "result": {
                "item": "# Dockerfile for LAMMPS (Large-scale Atomic/Molecular Massively Parallel Simulator)\n# Target Environment: Google Cloud CPU instance in Kubernetes\n# Base Image: Ubuntu 22.04 LTS for a stable and widely supported environment\nFROM ubuntu:22.04\n\n# Set DEBIAN_FRONTEND to noninteractive to prevent prompts during package installation\nENV DEBIAN_FRONTEND=noninteractive\n\n# Install build dependencies for LAMMPS\n# Includes git for cloning, cmake/build-essential for compiling,\n# and OpenMPI for parallel processing on CPU clusters.\n# FFTW is a common dependency for many LAMMPS packages.\n# CORRECTED: Added ca-certificates to allow git to verify SSL certificates for HTTPS clones.\n# The apt cache is cleaned in the same layer to reduce image size.\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    build-essential \\\n    cmake \\\n    git \\\n    libopenmpi-dev \\\n    openmpi-bin \\\n    libfftw3-dev \\\n    python3-dev \\\n    ca-certificates \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Configure OpenMPI for containerized environments like Docker and Kubernetes.\n# These settings are critical for running MPI jobs in containers:\n# - btl_tcp_if_exclude: Prevents MPI from using internal container network interfaces.\n# - orte_allow_run_as_root: Allows MPI processes to be launched by the root user, as is common in containers.\n# - rmaps_base_oversubscribe: Allows running more MPI processes than available CPU cores, useful for node sharing.\nRUN echo \"btl_tcp_if_exclude = lo,docker0\" >> /etc/openmpi/openmpi-mca-params.conf && \\\n    echo \"orte_allow_run_as_root = 1\" >> /etc/openmpi/openmpi-mca-params.conf && \\\n    echo \"rmaps_base_oversubscribe = 1\" >> /etc/openmpi/openmpi-mca-params.conf\n\n# Clone, build, and install LAMMPS from the latest branch in a single RUN layer.\n# This approach adheres to the no-multistage-build requirement.\n# --depth 1 is used to clone only the latest commit, speeding up the build.\n# A selection of common packages (KSPACE, MOLECULE, RIGID, REAXFF) is enabled for a robust, general-purpose build.\n# The executable 'lmp' will be installed to /usr/local/bin, which is on the system PATH.\nRUN git clone --depth 1 https://github.com/lammps/lammps.git /tmp/lammps && \\\n    cd /tmp/lammps && \\\n    mkdir build && \\\n    cd build && \\\n    cmake ../cmake \\\n        -D CMAKE_INSTALL_PREFIX=/usr/local \\\n        -D CMAKE_BUILD_TYPE=Release \\\n        -D BUILD_MPI=yes \\\n        -D PKG_KSPACE=yes \\\n        -D PKG_MOLECULE=yes \\\n        -D PKG_RIGID=yes \\\n        -D PKG_REAXFF=yes && \\\n    make -j$(nproc) && \\\n    make install\n\n# Set a working directory for running simulations.\nWORKDIR /opt/lammps_run\n\n# As requested, copy all files from the LAMMPS example 'examples/reaxff/HNS'\n# into the working directory, making them readily available for test runs.\nRUN cp /tmp/lammps/examples/reaxff/HNS/* .\n\n# Set the default command to an interactive bash shell.\n# This allows a user to easily exec into the container and launch LAMMPS simulations.\n# The LAMMPS executable 'lmp' is on the PATH and can be run directly.\n# Example usage: mpirun -np 4 lmp -in in.hns\nCMD [\"/bin/bash\"]",
                "total_seconds": 231.4147139559991,
                "type": "dockerfile"
            }
        }
    },
    {
        "agent": "kubernetes-job",
        "total_seconds": 48.951056320000134,
        "result": "# Job manifest for running a LAMMPS simulation on a Google Cloud CPU instance in Kubernetes.\n# This is designed to be a robust, production-ready configuration.\napiVersion: batch/v1\nkind: Job\nmetadata:\n  # The name of the Job. Must be unique within the namespace.\n  name: lammps-reaxff-hns-job\n  # Deploying to the 'default' namespace as requested.\n  namespace: default\nspec:\n  # The number of times a Job should be retried before marking it as failed.\n  # Set to 1 as requested, meaning it will run a maximum of two times (initial + 1 retry).\n  backoffLimit: 1\n  # The template for the Pods that the Job will create.\n  template:\n    spec:\n      containers:\n      - name: lammps # The exact container name as requested.\n        # The Docker image to use. This assumes an image named 'lammps' exists.\n        image: lammps\n        # imagePullPolicy is set to 'Never' as requested.\n        # This means the image must already be present on the node where the Pod is scheduled.\n        imagePullPolicy: Never\n        # The command to execute, assuming 'lmp' is in the system's PATH.\n        command: [\"lmp\"]\n        # The arguments for the command, structured for YAML.\n        # Runs the 'in.reaxff.hns' input file with specified variables.\n        args:\n        - \"-v\"\n        - \"x\"\n        - \"2\"\n        - \"-v\"\n        - \"y\"\n        - \"2\"\n        - \"-v\"\n        - \"z\"\n        - \"2\"\n        - \"-in\"\n        - \"./in.reaxff.hns\"\n        - \"-nocite\"\n        # Resource requests and limits are critical for scheduling and stability in a production cloud environment.\n        # This ensures the Pod gets the CPU it needs and doesn't consume more than its share.\n        resources:\n          requests:\n            # Request 1 full CPU core for scheduling.\n            cpu: \"1\"\n          limits:\n            # Limit the container to a maximum of 1 full CPU core.\n            cpu: \"1\"\n      # The restart policy for Pods in the Job.\n      # 'OnFailure' ensures the Pod restarts if the container fails, up to the backoffLimit.\n      # 'Never' would mean the Job fails immediately on any container failure.\n      restartPolicy: OnFailure",
        "attempts": 1,
        "metadata": {
            "times": {
                "generate_job_manifest_seconds": [
                    19.29814992199863
                ],
                "deploy_seconds": [
                    29.64465919000031
                ],
                "run_step_seconds": [
                    48.95102131100066
                ]
            },
            "assets": {
                "kubernetes-job-manifest": [
                    {
                        "item": "# Job manifest for running a LAMMPS simulation on a Google Cloud CPU instance in Kubernetes.\n# This is designed to be a robust, production-ready configuration.\napiVersion: batch/v1\nkind: Job\nmetadata:\n  # The name of the Job. Must be unique within the namespace.\n  name: lammps-reaxff-hns-job\n  # Deploying to the 'default' namespace as requested.\n  namespace: default\nspec:\n  # The number of times a Job should be retried before marking it as failed.\n  # Set to 1 as requested, meaning it will run a maximum of two times (initial + 1 retry).\n  backoffLimit: 1\n  # The template for the Pods that the Job will create.\n  template:\n    spec:\n      containers:\n      - name: lammps # The exact container name as requested.\n        # The Docker image to use. This assumes an image named 'lammps' exists.\n        image: lammps\n        # imagePullPolicy is set to 'Never' as requested.\n        # This means the image must already be present on the node where the Pod is scheduled.\n        imagePullPolicy: Never\n        # The command to execute, assuming 'lmp' is in the system's PATH.\n        command: [\"lmp\"]\n        # The arguments for the command, structured for YAML.\n        # Runs the 'in.reaxff.hns' input file with specified variables.\n        args:\n        - \"-v\"\n        - \"x\"\n        - \"2\"\n        - \"-v\"\n        - \"y\"\n        - \"2\"\n        - \"-v\"\n        - \"z\"\n        - \"2\"\n        - \"-in\"\n        - \"./in.reaxff.hns\"\n        - \"-nocite\"\n        # Resource requests and limits are critical for scheduling and stability in a production cloud environment.\n        # This ensures the Pod gets the CPU it needs and doesn't consume more than its share.\n        resources:\n          requests:\n            # Request 1 full CPU core for scheduling.\n            cpu: \"1\"\n          limits:\n            # Limit the container to a maximum of 1 full CPU core.\n            cpu: \"1\"\n      # The restart policy for Pods in the Job.\n      # 'OnFailure' ensures the Pod restarts if the container fails, up to the backoffLimit.\n      # 'Never' would mean the Job fails immediately on any container failure.\n      restartPolicy: OnFailure",
                        "attempt": 0
                    }
                ],
                "logs": [
                    {
                        "item": "LAMMPS (22 Jul 2025 - Development - 57ae282)\nOMP_NUM_THREADS environment is not set. Defaulting to 1 thread.\n  using 1 OpenMP thread(s) per MPI task\nReading data file ...\n  triclinic box = (0 0 0) to (22.326 11.1412 13.778966) with tilt (0 -5.02603 0)\n  1 by 1 by 1 MPI processor grid\n  reading atoms ...\n  304 atoms\n  reading velocities ...\n  304 velocities\n  read_data CPU = 0.003 seconds\nReplication is creating a 2x2x2 = 8 times larger system...\n  triclinic box = (0 0 0) to (44.652 22.2824 27.557932) with tilt (0 -10.05206 0)\n  1 by 1 by 1 MPI processor grid\n  bounding box image = (0 -1 -1) to (0 1 1)\n  bounding box extra memory = 0.03 MB\n  average # of replicas added to proc = 8.00 out of 8 (100.00%)\n  2432 atoms\n  replicate CPU = 0.001 seconds\nNeighbor list info ...\n  update: every = 20 steps, delay = 0 steps, check = no\n  max neighbors/atom: 2000, page size: 100000\n  master list distance cutoff = 11\n  ghost atom cutoff = 11\n  binsize = 5.5, bins = 10 5 6\n  2 neighbor lists, perpetual/occasional/extra = 2 0 0\n  (1) pair reaxff, perpetual\n      attributes: half, newton off, ghost\n      pair build: half/bin/ghost/newtoff\n      stencil: full/ghost/bin/3d\n      bin: standard\n  (2) fix qeq/reax, perpetual, copy from (1)\n      attributes: half, newton off\n      pair build: copy\n      stencil: none\n      bin: none\nSetting up Verlet run ...\n  Unit style    : real\n  Current step  : 0\n  Time step     : 0.1\nPer MPI rank memory allocation (min/avg/max) = 215 | 215 | 215 Mbytes\n   Step          Temp          PotEng         Press          E_vdwl         E_coul         Volume    \n         0   300           -113.27833      437.52149     -111.57687     -1.7014647      27418.867    \n        10   299.38517     -113.27631      1439.2564     -111.57492     -1.7013814      27418.867    \n        20   300.27107     -113.27884      3764.4017     -111.57762     -1.7012246      27418.867    \n        30   302.21064     -113.28428      7007.6558     -111.58335     -1.7009364      27418.867    \n        40   303.52265     -113.28799      9844.8196     -111.58747     -1.7005186      27418.867    \n        50   301.8706      -113.28324      9663.08       -111.58318     -1.7000523      27418.867    \n        60   296.67808     -113.26777      7273.8875     -111.56815     -1.6996136      27418.867    \n        70   292.19999     -113.25435      5533.625      -111.55514     -1.6992157      27418.867    \n        80   293.58678     -113.25831      5993.4679     -111.55946     -1.6988532      27418.867    \n        90   300.62637     -113.27925      7202.8453     -111.58069     -1.6985592      27418.867    \n       100   305.38277     -113.29357      10085.747     -111.59518     -1.6983875      27418.867    \nLoop time of 17.2135 on 1 procs for 100 steps with 2432 atoms\n\nPerformance: 0.050 ns/day, 478.154 hours/ns, 5.809 timesteps/s, 14.128 katom-step/s\n99.8% CPU use with 1 MPI tasks x 1 OpenMP threads\n\nMPI task timing breakdown:\nSection |  min time  |  avg time  |  max time  |%varavg| %total\n---------------------------------------------------------------\nPair    | 12.716     | 12.716     | 12.716     |   0.0 | 73.87\nNeigh   | 0.27098    | 0.27098    | 0.27098    |   0.0 |  1.57\nComm    | 0.0074988  | 0.0074988  | 0.0074988  |   0.0 |  0.04\nOutput  | 0.00029694 | 0.00029694 | 0.00029694 |   0.0 |  0.00\nModify  | 4.2176     | 4.2176     | 4.2176     |   0.0 | 24.50\nOther   |            | 0.0009168  |            |       |  0.01\n\nNlocal:           2432 ave        2432 max        2432 min\nHistogram: 1 0 0 0 0 0 0 0 0 0\nNghost:          10685 ave       10685 max       10685 min\nHistogram: 1 0 0 0 0 0 0 0 0 0\nNeighs:         823958 ave      823958 max      823958 min\nHistogram: 1 0 0 0 0 0 0 0 0 0\n\nTotal # of neighbors = 823958\nAve neighs/atom = 338.79852\nNeighbor list builds = 5\nDangerous builds not checked\nTotal wall time: 0:00:17\n",
                        "attempt": 0
                    }
                ]
            },
            "ask_gemini": [
                {
                    "conversation_history": true,
                    "prompt_token_count": 329,
                    "candidates_token_count": 571,
                    "total_token_count": 2381,
                    "time_seconds": 19.29546275499888
                }
            ],
            "retries": 0,
            "result": {
                "item": "# Job manifest for running a LAMMPS simulation on a Google Cloud CPU instance in Kubernetes.\n# This is designed to be a robust, production-ready configuration.\napiVersion: batch/v1\nkind: Job\nmetadata:\n  # The name of the Job. Must be unique within the namespace.\n  name: lammps-reaxff-hns-job\n  # Deploying to the 'default' namespace as requested.\n  namespace: default\nspec:\n  # The number of times a Job should be retried before marking it as failed.\n  # Set to 1 as requested, meaning it will run a maximum of two times (initial + 1 retry).\n  backoffLimit: 1\n  # The template for the Pods that the Job will create.\n  template:\n    spec:\n      containers:\n      - name: lammps # The exact container name as requested.\n        # The Docker image to use. This assumes an image named 'lammps' exists.\n        image: lammps\n        # imagePullPolicy is set to 'Never' as requested.\n        # This means the image must already be present on the node where the Pod is scheduled.\n        imagePullPolicy: Never\n        # The command to execute, assuming 'lmp' is in the system's PATH.\n        command: [\"lmp\"]\n        # The arguments for the command, structured for YAML.\n        # Runs the 'in.reaxff.hns' input file with specified variables.\n        args:\n        - \"-v\"\n        - \"x\"\n        - \"2\"\n        - \"-v\"\n        - \"y\"\n        - \"2\"\n        - \"-v\"\n        - \"z\"\n        - \"2\"\n        - \"-in\"\n        - \"./in.reaxff.hns\"\n        - \"-nocite\"\n        # Resource requests and limits are critical for scheduling and stability in a production cloud environment.\n        # This ensures the Pod gets the CPU it needs and doesn't consume more than its share.\n        resources:\n          requests:\n            # Request 1 full CPU core for scheduling.\n            cpu: \"1\"\n          limits:\n            # Limit the container to a maximum of 1 full CPU core.\n            cpu: \"1\"\n      # The restart policy for Pods in the Job.\n      # 'OnFailure' ensures the Pod restarts if the container fails, up to the backoffLimit.\n      # 'Never' would mean the Job fails immediately on any container failure.\n      restartPolicy: OnFailure",
                "total_seconds": 48.95103350700083,
                "type": "kubernetes-job-manifest"
            }
        }
    }
]